{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e37e8f3f915242d5b64dc0b84c015cb5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d5f5f25dc244940ab8ca8ed26b834f7","IPY_MODEL_297f2686f538448aa3305beeb831aa89","IPY_MODEL_4b895e1f43ae42978cd9c91fde195b42"],"layout":"IPY_MODEL_a3ca77e672da4665bfbbab6c20a7654e"}},"0d5f5f25dc244940ab8ca8ed26b834f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b51aaccbfcb4ac799a519cd6e18cfd0","placeholder":"​","style":"IPY_MODEL_26cf6ceeb94b4de7bda633bfe665a534","value":"tokenizer_config.json: 100%"}},"297f2686f538448aa3305beeb831aa89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffe5a47a9fcd4f9ab1186c3fc3c47cb3","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e01fb8997e7e48e1a79dcd4792573ab7","value":48}},"4b895e1f43ae42978cd9c91fde195b42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17a666ec765d4a36b7ef20115fef6c79","placeholder":"​","style":"IPY_MODEL_9bd287d28c8d4976916e5da4a755d135","value":" 48.0/48.0 [00:00&lt;00:00, 4.78kB/s]"}},"a3ca77e672da4665bfbbab6c20a7654e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b51aaccbfcb4ac799a519cd6e18cfd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26cf6ceeb94b4de7bda633bfe665a534":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffe5a47a9fcd4f9ab1186c3fc3c47cb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e01fb8997e7e48e1a79dcd4792573ab7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17a666ec765d4a36b7ef20115fef6c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bd287d28c8d4976916e5da4a755d135":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"417537fcf82b4346b171b29b46f82ae0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b08f431f15941f5b0ecd6595e774907","IPY_MODEL_7f2c9ee2d800465f989b01c2fe151218","IPY_MODEL_1fd99f18b21045eaa714ab8197d4720e"],"layout":"IPY_MODEL_04a8b0c0e233412094d43663eaea68ff"}},"4b08f431f15941f5b0ecd6595e774907":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ec855b173b146f1ad1145fad9df3a90","placeholder":"​","style":"IPY_MODEL_c9ebc61956bc4d40a5fc258f9f4a15ef","value":"vocab.txt: 100%"}},"7f2c9ee2d800465f989b01c2fe151218":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b5b232b7e2a4c66a6e6a7c8901e9dc8","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5d312fb4e1641a5a7bea62456f99fe9","value":231508}},"1fd99f18b21045eaa714ab8197d4720e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2beb79c0627c4c6a9122f9b68314316a","placeholder":"​","style":"IPY_MODEL_f4f49846947241a880e62d8b13bd6c83","value":" 232k/232k [00:00&lt;00:00, 16.3MB/s]"}},"04a8b0c0e233412094d43663eaea68ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ec855b173b146f1ad1145fad9df3a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9ebc61956bc4d40a5fc258f9f4a15ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b5b232b7e2a4c66a6e6a7c8901e9dc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5d312fb4e1641a5a7bea62456f99fe9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2beb79c0627c4c6a9122f9b68314316a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4f49846947241a880e62d8b13bd6c83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f116221591694a4aa6cc4b6a04ce7057":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_beb12108bca74231b1c58654bc4adbb7","IPY_MODEL_8744eea355b74bab80ee82740e7baed7","IPY_MODEL_0cd16a761cb744b6916d89f9097c593b"],"layout":"IPY_MODEL_acdcdcadc6e443df901a2683e6226985"}},"beb12108bca74231b1c58654bc4adbb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b480be75f62b42b19687fa099ff3207f","placeholder":"​","style":"IPY_MODEL_dedc68cdcccf474ca6ea94aec29a01bc","value":"tokenizer.json: 100%"}},"8744eea355b74bab80ee82740e7baed7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb166bddc11849c092814e973f71853f","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cb97e58aef44180963934a86f78eecf","value":466062}},"0cd16a761cb744b6916d89f9097c593b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e683db92ba842e2b0931c248a32fa51","placeholder":"​","style":"IPY_MODEL_e35dc6e9f7de428c87660938787767e5","value":" 466k/466k [00:00&lt;00:00, 30.5MB/s]"}},"acdcdcadc6e443df901a2683e6226985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b480be75f62b42b19687fa099ff3207f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dedc68cdcccf474ca6ea94aec29a01bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb166bddc11849c092814e973f71853f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cb97e58aef44180963934a86f78eecf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e683db92ba842e2b0931c248a32fa51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e35dc6e9f7de428c87660938787767e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dce708aad43c4c9fae5a4c18a6f23aa8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_483acd5b8c7f46cfbd9057c474cc6b5f","IPY_MODEL_65d6a762fd99478da40d0e618538f7bf","IPY_MODEL_210c59458a67461b9495e43c5476aaa4"],"layout":"IPY_MODEL_07b30e9c7ae145b7b521b585bff8bda8"}},"483acd5b8c7f46cfbd9057c474cc6b5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_354aceb6f167459a922854027bf922fc","placeholder":"​","style":"IPY_MODEL_cd0167a109ec4d4a91269ed8c49e6c8c","value":"config.json: 100%"}},"65d6a762fd99478da40d0e618538f7bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aa113c1656f4e598ddea9eafcbf579c","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2053ed0518c9487fbdd61cdfd56585b5","value":570}},"210c59458a67461b9495e43c5476aaa4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66b4a8f908b8480291001dd0bc9894c9","placeholder":"​","style":"IPY_MODEL_7f050f5ad4de4bb4a5ee5d5c07f5994e","value":" 570/570 [00:00&lt;00:00, 42.1kB/s]"}},"07b30e9c7ae145b7b521b585bff8bda8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"354aceb6f167459a922854027bf922fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd0167a109ec4d4a91269ed8c49e6c8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9aa113c1656f4e598ddea9eafcbf579c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2053ed0518c9487fbdd61cdfd56585b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66b4a8f908b8480291001dd0bc9894c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f050f5ad4de4bb4a5ee5d5c07f5994e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0018c5600e7d4661a9ac2f4408e962a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b97caa1554548168034073f5e7fe85a","IPY_MODEL_7a856d561fe2478d9430fe786e7d35c9","IPY_MODEL_5e52dd92421a47eebc9b4b3082800cca"],"layout":"IPY_MODEL_549f233266554201851b3dcfdd5ff1c3"}},"7b97caa1554548168034073f5e7fe85a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_321d72eb76e7454db8f9f0911a5eba64","placeholder":"​","style":"IPY_MODEL_1251476a0805423082651f0d2613c0cf","value":"model.safetensors: 100%"}},"7a856d561fe2478d9430fe786e7d35c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aae3ccf74ae7480ab7c621ece617e8d5","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34c2764c9cd5475a9c0186bf762b6e9a","value":440449768}},"5e52dd92421a47eebc9b4b3082800cca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfa8a7bd49954c4db916933f148203de","placeholder":"​","style":"IPY_MODEL_5e2dbe7133b340059e7456f85d2afa1b","value":" 440M/440M [00:01&lt;00:00, 206MB/s]"}},"549f233266554201851b3dcfdd5ff1c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"321d72eb76e7454db8f9f0911a5eba64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1251476a0805423082651f0d2613c0cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aae3ccf74ae7480ab7c621ece617e8d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34c2764c9cd5475a9c0186bf762b6e9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cfa8a7bd49954c4db916933f148203de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e2dbe7133b340059e7456f85d2afa1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AV-noix4Qu0C","executionInfo":{"status":"ok","timestamp":1741752648512,"user_tz":240,"elapsed":15094,"user":{"displayName":"Wenda Zhai","userId":"16839433519852049027"}},"outputId":"06a91945-ea48-413b-ee21-f9647fc5ef0a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["# 1. Environment Setup\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from transformers import BertTokenizer, BertModel\n","from transformers import logging as transformers_logging\n","transformers_logging.set_verbosity_error()  # Suppress warnings from transformers\n","\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","from bs4 import BeautifulSoup\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from torch.nn import Parameter\n","import pandas as pd\n","import numpy as np\n","import string\n","from collections import Counter\n","from tqdm import tqdm\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"markdown","source":["The TextPreprocessor class is crafted to transform raw textual data into a format that is both clean and compatible with advanced NLP models like BERT.\n","\n","Each method within the class serves a distinct purpose, collectively ensuring that the data is well-prepared for effective model training, validation, and testing."],"metadata":{"id":"XLEuLNKxbVx3"}},{"cell_type":"code","source":["# 2. Data Preprocessing\n","class TextPreprocessor:\n","    def __init__(self, pretrained_model_name='bert-base-uncased', max_len=50):\n","        \"\"\"\n","        Initializes the TextPreprocessor with BERT's tokenizer.\n","\n","        Args:\n","            pretrained_model_name (str): Name of the pre-trained BERT model.\n","            max_len (int): Maximum length for padding/truncating sequences.\n","        \"\"\"\n","        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n","        self.max_len = max_len\n","        self.label_mapping = {'neutral': 0, 'positive': 1, 'negative': 2}\n","\n","    def clean_text(self, text):\n","        \"\"\"\n","        Cleans the input text by removing HTML tags and punctuation.\n","        Args: text (str): The raw text data to clean.\n","        Returns: str: The cleaned text.\n","        \"\"\"\n","        text = BeautifulSoup(text, \"html.parser\").get_text() # Remove HTML tags\n","        text = text.lower() # Convert to lowercase\n","        text = text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation\n","        return text\n","\n","    def split_data(self, df, text_column, label_column, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n","        \"\"\"\n","        Splits the dataset into train, validation, and test sets.\n","\n","        Args:\n","            df (pd.DataFrame): The input DataFrame with text and labels.\n","            text_column (str): The name of the column containing text data.\n","            label_column (str): The name of the column containing label data.\n","            train_ratio (float): Proportion of the dataset for training.\n","            val_ratio (float): Proportion of the dataset for validation.\n","            test_ratio (float): Proportion of the dataset for testing.\n","\n","        Returns:\n","            tuple: Train, validation, and test DataFrames.\n","        \"\"\"\n","        assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1.\"\n","\n","        # Split into train and temp (validation + test)\n","        train_data, temp_data = train_test_split(df, test_size=val_ratio + test_ratio, random_state=42, stratify=df[label_column])\n","        # Split temp into validation and test\n","        val_data, test_data = train_test_split(temp_data, test_size=test_ratio / (val_ratio + test_ratio), random_state=42, stratify=temp_data[label_column])\n","        return train_data, val_data, test_data\n","\n","    def encode_labels(self, df, label_column):\n","        \"\"\"\n","        Encodes string labels to numeric values.\n","\n","        Args:\n","            df (pd.DataFrame): Input DataFrame with string labels.\n","            label_column (str): Column containing the labels.\n","\n","        Returns:\n","            pd.DataFrame: DataFrame with numeric labels.\n","        \"\"\"\n","        df[label_column] = df[label_column].map(self.label_mapping)\n","        return df\n","\n","    def tokenize_and_encode(self, texts):\n","        \"\"\"\n","        Tokenizes and encodes the texts using BERT's tokenizer.\n","\n","        Args:\n","            texts (list of str): List of text samples.\n","\n","        Returns:\n","            dict: Dictionary containing input_ids and attention_mask.\n","        \"\"\"\n","        return self.tokenizer(\n","            texts,\n","            padding='max_length',\n","            truncation=True,\n","            max_length=self.max_len,\n","            return_tensors='pt'\n","        )\n","\n","    def preprocess_dataset(self, df, text_column, label_column):\n","        \"\"\"\n","        Cleans text data and encodes labels.\n","\n","        Args:\n","            df (pd.DataFrame): Input DataFrame with text and labels.\n","            text_column (str): Column with text data.\n","            label_column (str): Column with labels.\n","\n","        Returns:\n","            tuple: Train, validation, and test datasets with input_ids, attention_mask, and labels.\n","        \"\"\"\n","        print(\"Cleaning text data...\")\n","        df[text_column] = df[text_column].apply(self.clean_text)\n","\n","        print(\"Encoding labels...\")\n","        df = self.encode_labels(df, label_column)\n","\n","        print(\"Splitting dataset into train, validation, and test sets...\")\n","        train_data, val_data, test_data = self.split_data(df, text_column, label_column)\n","\n","        print(\"Tokenizing and encoding text data...\")\n","        train_encodings = self.tokenize_and_encode(train_data[text_column].tolist())\n","        val_encodings = self.tokenize_and_encode(val_data[text_column].tolist())\n","        test_encodings = self.tokenize_and_encode(test_data[text_column].tolist())\n","\n","        train_labels = torch.tensor(train_data[label_column].values)\n","        val_labels = torch.tensor(val_data[label_column].values)\n","        test_labels = torch.tensor(test_data[label_column].values)\n","\n","        print(f\"Train set: {len(train_data)} samples\")\n","        print(f\"Validation set: {len(val_data)} samples\")\n","        print(f\"Test set: {len(test_data)} samples\")\n","\n","        return (train_encodings['input_ids'], train_encodings['attention_mask'], train_labels,\n","                val_encodings['input_ids'], val_encodings['attention_mask'], val_labels,\n","                test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)"],"metadata":{"id":"q-hMl5nDbUrX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**How To Call the method**\n","\n","preprocessor = TextPreprocessor()\n","train_sequences, train_labels, val_sequences, val_labels, test_sequences, test_labels = preprocessor.preprocess_dataset(\n","    org_data, text_column='Sentence', label_column='Sentiment', max_len=50\n",")\n","\n","print(f\"\\nVocabulary size: {len(preprocessor.vocab)}\")\n","print(f\"First 5 training sequences: {train_sequences[:5]}\")\n","print(f\"First 5 training labels: {train_labels[:5]}\")\n"],"metadata":{"id":"CiAL3pDUcEWf"}},{"cell_type":"code","source":["# 3. Quaternion Classes\n","\n","class Quaternion:\n","    \"\"\"\n","    A class to represent and operate on quaternions.\n","    Supports initialization, Hamilton product, addition, normalization, and conjugation.\n","    \"\"\"\n","\n","    def __init__(self, tensor):\n","        \"\"\"\n","        Initialize with a tensor that will be split into quaternion components.\n","        The tensor's last dimension is assumed to represent concatenated quaternion components\n","        (r, i, j, k), with its size divisible by 4.\n","\n","        Args:\n","            tensor (torch.Tensor): A tensor with quaternion components concatenated along the last dimension.\n","        \"\"\"\n","        self.tensor = tensor\n","        self.r, self.i, self.j, self.k = torch.split(self.tensor, self.tensor.shape[-1] // 4, dim=-1)\n","\n","    @classmethod\n","    def from_components(cls, r, i, j, k):\n","        \"\"\"\n","        Create a Quaternion object from separate r, i, j, k component tensors.\n","\n","        Args:\n","            r (torch.Tensor): Real component.\n","            i (torch.Tensor): First imaginary component.\n","            j (torch.Tensor): Second imaginary component.\n","            k (torch.Tensor): Third imaginary component.\n","\n","        Returns:\n","            Quaternion: A quaternion object created from the input components.\n","        \"\"\"\n","        tensor = torch.cat([r, i, j, k], dim=-1)\n","        return cls(tensor)\n","\n","    def hamilton_product(self, other):\n","        \"\"\"\n","        Perform Hamilton product (quaternion multiplication) between this quaternion\n","        and another quaternion using either element-wise or matrix multiplication.\n","\n","        Args:\n","            other (Quaternion): Another quaternion.\n","\n","        Returns:\n","            torch.Tensor: A tensor representing the resulting quaternion components (r, i, j, k).\n","        \"\"\"\n","        r2, i2, j2, k2 = other.r, other.i, other.j, other.k\n","\n","        if self.r.dim() == 2 and r2.dim() == 2 and self.r.shape[-1] == r2.shape[-2]:\n","            # Matrix multiplication\n","            r = torch.matmul(self.r, r2) - torch.matmul(self.i, i2) - torch.matmul(self.j, j2) - torch.matmul(self.k, k2)\n","            i = torch.matmul(self.r, i2) + torch.matmul(self.i, r2) + torch.matmul(self.j, k2) - torch.matmul(self.k, j2)\n","            j = torch.matmul(self.r, j2) - torch.matmul(self.i, k2) + torch.matmul(self.j, r2) + torch.matmul(self.k, i2)\n","            k = torch.matmul(self.r, k2) + torch.matmul(self.i, j2) - torch.matmul(self.j, i2) + torch.matmul(self.k, r2)\n","        else:\n","            # Element-wise multiplication\n","            r = self.r * r2 - self.i * i2 - self.j * j2 - self.k * k2\n","            i = self.r * i2 + self.i * r2 + self.j * k2 - self.k * j2\n","            j = self.r * j2 - self.i * k2 + self.j * r2 + self.k * i2\n","            k = self.r * k2 + self.i * j2 - self.j * i2 + self.k * r2\n","\n","        return Quaternion(torch.cat([r, i, j, k], dim=-1)).as_tensor()\n","\n","    def hamilton_product_quaternion(self, other):\n","        \"\"\"\n","        Perform Hamilton product and return the result as a Quaternion object.\n","\n","        Args:\n","            other (Quaternion): Another quaternion.\n","\n","        Returns:\n","            Quaternion: A new quaternion representing the product.\n","        \"\"\"\n","        r2, i2, j2, k2 = other.r, other.i, other.j, other.k\n","\n","        if self.r.dim() == 2 and r2.dim() == 2 and self.r.shape[-1] == r2.shape[-2]:\n","            r = torch.matmul(self.r, r2) - torch.matmul(self.i, i2) - torch.matmul(self.j, j2) - torch.matmul(self.k, k2)\n","            i = torch.matmul(self.r, i2) + torch.matmul(self.i, r2) + torch.matmul(self.j, k2) - torch.matmul(self.k, j2)\n","            j = torch.matmul(self.r, j2) - torch.matmul(self.i, k2) + torch.matmul(self.j, r2) + torch.matmul(self.k, i2)\n","            k = torch.matmul(self.r, k2) + torch.matmul(self.i, j2) - torch.matmul(self.j, i2) + torch.matmul(self.k, r2)\n","        else:\n","            r = self.r * r2 - self.i * i2 - self.j * j2 - self.k * k2\n","            i = self.r * i2 + self.i * r2 + self.j * k2 - self.k * j2\n","            j = self.r * j2 - self.i * k2 + self.j * r2 + self.k * i2\n","            k = self.r * k2 + self.i * j2 - self.j * i2 + self.k * r2\n","\n","        return Quaternion(torch.cat([r, i, j, k], dim=-1))\n","\n","    def add(self, other):\n","        \"\"\"\n","        Perform component-wise addition between two quaternions.\n","\n","        Args:\n","            other (Quaternion): Another quaternion.\n","\n","        Returns:\n","            Quaternion: A quaternion representing the sum.\n","        \"\"\"\n","        r = self.r + other.r\n","        i = self.i + other.i\n","        j = self.j + other.j\n","        k = self.k + other.k\n","\n","        return Quaternion(torch.cat([r, i, j, k], dim=-1))\n","\n","    def normalize(self):\n","        \"\"\"\n","        Normalize the quaternion to have unit norm.\n","\n","        Returns:\n","            Quaternion: A normalized quaternion.\n","        \"\"\"\n","        norm = torch.sqrt(self.r ** 2 + self.i ** 2 + self.j ** 2 + self.k ** 2)\n","        return Quaternion(torch.cat([self.r / norm, self.i / norm, self.j / norm, self.k / norm], dim=-1))\n","\n","    def conjugate(self):\n","        \"\"\"\n","        Return the conjugate of the quaternion: (r, -i, -j, -k).\n","\n","        Returns:\n","            Quaternion: The conjugated quaternion.\n","        \"\"\"\n","        return Quaternion(torch.cat([self.r, -self.i, -self.j, -self.k], dim=-1))\n","\n","    def as_tensor(self):\n","        \"\"\"\n","        Return the quaternion as a single concatenated tensor (r, i, j, k components).\n","        If the tensor is 2D, unsqueeze it to add a batch dimension of 1.\n","\n","        Returns:\n","            torch.Tensor: The concatenated quaternion tensor.\n","        \"\"\"\n","        tensor = torch.cat([self.r, self.i, self.j, self.k], dim=-1)\n","        if tensor.ndim == 2:\n","            tensor = tensor.unsqueeze(0)\n","        return tensor\n","\n","\n","class QuaternionTransformation(nn.Module):\n","    \"\"\"\n","    A PyTorch module for applying a quaternion transformation to input data using\n","    learnable quaternion weights. Supports optional activation functions.\n","    \"\"\"\n","\n","    def __init__(self, input_dim, output_dim, activation=None, init=None):\n","        \"\"\"\n","        Initialize the QuaternionTransformation module.\n","\n","        Args:\n","            input_dim (int): Dimensionality of the input tensor (must be divisible by 4).\n","            output_dim (int): Desired output dimensionality (number of quaternion features).\n","            activation (callable, optional): Activation function to apply after transformation.\n","            init (callable, optional): Initialization function for quaternion weights. Defaults to Xavier uniform.\n","        \"\"\"\n","        super(QuaternionTransformation, self).__init__()\n","\n","        # Quaternion input dimension is divided by 4 (for r, i, j, k components)\n","        self.input_dim = input_dim // 4\n","        self.output_dim = output_dim\n","        self.activation = activation\n","\n","        # Learnable quaternion weight matrices for r, i, j, k components\n","        self.r_weight = Parameter(torch.Tensor(self.input_dim, self.output_dim))\n","        self.i_weight = Parameter(torch.Tensor(self.input_dim, self.output_dim))\n","        self.j_weight = Parameter(torch.Tensor(self.input_dim, self.output_dim))\n","        self.k_weight = Parameter(torch.Tensor(self.input_dim, self.output_dim))\n","\n","        # Initialize the weights\n","        if init is None:\n","            nn.init.xavier_uniform_(self.r_weight)\n","            nn.init.xavier_uniform_(self.i_weight)\n","            nn.init.xavier_uniform_(self.j_weight)\n","            nn.init.xavier_uniform_(self.k_weight)\n","        else:\n","            # Apply custom initialization if provided\n","            self.r_weight.data = init(self.r_weight.data)\n","            self.i_weight.data = init(self.i_weight.data)\n","            self.j_weight.data = init(self.j_weight.data)\n","            self.k_weight.data = init(self.k_weight.data)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Perform the quaternion transformation on the input tensor.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor of shape [batch_size, seq_len, input_dim] (3D)\n","                              or [batch_size, input_dim] (2D). The last dimension must\n","                              be divisible by 4 for quaternion processing.\n","\n","        Returns:\n","            torch.Tensor: Output tensor of shape [batch_size, seq_len, output_dim * 4] (for 3D input)\n","                          or [batch_size, output_dim * 4] (for 2D input), representing\n","                          the transformed quaternion components (r, i, j, k).\n","        \"\"\"\n","        is_3d_input = x.ndim == 3  # Check if the input is 3D\n","\n","        if is_3d_input:\n","            # Flatten 3D input to 2D for processing\n","            batch_size, seq_len, input_dim = x.shape\n","            x = x.view(batch_size * seq_len, input_dim)\n","\n","        # Convert input tensor into quaternion components (r, i, j, k)\n","        q_x = Quaternion(x)\n","\n","        # Create a quaternion from the learnable weights\n","        q_kernel = Quaternion.from_components(self.r_weight, self.i_weight, self.j_weight, self.k_weight)\n","\n","        # Perform Hamilton product (quaternion multiplication)\n","        hamilton_product_result = q_x.hamilton_product(q_kernel)\n","\n","        # Apply activation function if provided\n","        if self.activation is not None:\n","            output = self.activation(hamilton_product_result)\n","        else:\n","            output = hamilton_product_result\n","\n","        if is_3d_input:\n","            # Reshape back to 3D if input was originally 3D\n","            return output.view(batch_size, seq_len, self.output_dim * 4)\n","\n","        return output\n","\n","class QuaternionSelfAttention(nn.Module):\n","    \"\"\"\n","    A PyTorch implementation of Quaternion Self-Attention for handling quaternion-valued data.\n","    This module applies quaternion-valued self-attention mechanisms using Hamilton product-based interactions.\n","\n","    Attributes:\n","        input_dim (int): The dimension of the input tensor.\n","        output_dim (int): The dimension of the output tensor.\n","        dropout_rate (float): The dropout rate applied to the attention weights.\n","        dk (int): Scaling factor for attention, equal to output_dim divided by 4.\n","        q_transform (QuaternionTransformation): Transformation layer for queries (Q).\n","        k_transform (QuaternionTransformation): Transformation layer for keys (K).\n","        v_transform (QuaternionTransformation): Transformation layer for values (V).\n","    \"\"\"\n","    def __init__(self, input_dim, output_dim, dropout_rate=0.0):\n","        \"\"\"\n","        Initializes the QuaternionSelfAttention module.\n","\n","        Args:\n","            input_dim (int): The dimension of the input tensor.\n","            output_dim (int): The dimension of the output tensor. Must be divisible by 4 for quaternion representation.\n","            dropout_rate (float): Dropout rate applied to attention weights. Default is 0.0.\n","        \"\"\"\n","        super(QuaternionSelfAttention, self).__init__()\n","\n","        # Ensure output_dim is divisible by 4 for quaternion representation\n","        assert output_dim % 4 == 0, \"output_dim must be divisible by 4 for quaternion representation.\"\n","\n","        self.output_dim = output_dim\n","        self.input_dim = input_dim\n","        self.dk = self.output_dim // 4\n","\n","        # Dropout rate\n","        self.dropout_rate = dropout_rate\n","\n","        # Quaternion linear transformations for Q, K, V\n","        self.q_transform = QuaternionTransformation(self.output_dim, self.output_dim // 4)\n","        self.k_transform = QuaternionTransformation(self.output_dim, self.output_dim // 4)\n","        self.v_transform = QuaternionTransformation(self.output_dim, self.output_dim // 4)\n","\n","    def quaternion_attention(self, a, b):\n","        \"\"\"\n","        Perform dot product attention between two quaternion sequences.\n","\n","        Args:\n","            a (torch.Tensor): The first quaternion tensor of shape [batch_size, seq_len_a, dim].\n","            b (torch.Tensor): The second quaternion tensor of shape [batch_size, seq_len_b, dim].\n","\n","        Returns:\n","            Quaternion: A quaternion object containing attention matrices for each quaternion component (r, i, j, k).\n","\n","        Note:\n","            The quaternion attention formula is based on Hamilton product:\n","            (rr' - xx' - yy' - zz')  +\n","            (rx' + xr' + yz' - zy')i +\n","            (ry' - xz' + yr' + zx')j +\n","            (rz' + xy' - yx' + zr')k\n","        \"\"\"\n","        # Ensure the input dimensions are divisible by 4\n","        assert a.size(-1) % 4 == 0, \"Last dimension of input tensor must be divisible by 4 for quaternion representation.\"\n","        assert b.size(-1) % 4 == 0, \"Last dimension of input tensor must be divisible by 4 for quaternion representation.\"\n","\n","        # Split inputs into quaternion components\n","        ar, ai, aj, ak = torch.chunk(a, 4, dim=-1)\n","        br, bi, bj, bk = torch.chunk(b, 4, dim=-1)\n","\n","        # Compute the quaternion Hamilton product\n","        r = (torch.matmul(ar, br.transpose(-1, -2))\n","             - torch.matmul(ai, bi.transpose(-1, -2))\n","             - torch.matmul(aj, bj.transpose(-1, -2))\n","             - torch.matmul(ak, bk.transpose(-1, -2)))\n","        i = (torch.matmul(ar, bi.transpose(-1, -2))\n","             + torch.matmul(ai, br.transpose(-1, -2))\n","             + torch.matmul(aj, bk.transpose(-1, -2))\n","             - torch.matmul(ak, bj.transpose(-1, -2)))\n","        j = (torch.matmul(ar, bj.transpose(-1, -2))\n","             - torch.matmul(ai, bk.transpose(-1, -2))\n","             + torch.matmul(aj, br.transpose(-1, -2))\n","             + torch.matmul(ak, bi.transpose(-1, -2)))\n","        k = (torch.matmul(ar, bk.transpose(-1, -2))\n","             + torch.matmul(ai, bj.transpose(-1, -2))\n","             - torch.matmul(aj, bi.transpose(-1, -2))\n","             + torch.matmul(ak, br.transpose(-1, -2)))\n","\n","        return Quaternion.from_components(r, i, j, k)\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Forward pass of the quaternion self-attention mechanism.\n","\n","        Args:\n","            X (torch.Tensor): Input tensor of shape [batch_size, seq_len, input_dim].\n","\n","        Returns:\n","            torch.Tensor: Output tensor after applying quaternion self-attention, of shape [batch_size, seq_len, output_dim].\n","        \"\"\"\n","        is_3d_input = X.ndim == 3\n","        if is_3d_input:\n","            batch_size, seq_len, dim = X.shape\n","\n","        # Compute quaternion transformations for Q, K, V\n","        Q = self.q_transform(X)  # Shape: [batch_size, seq_len, output_dim]\n","        K = self.k_transform(X)  # Shape: [batch_size, seq_len, output_dim]\n","        V = self.v_transform(X)  # Shape: [batch_size, seq_len, output_dim]\n","\n","        # Split V into quaternion components\n","        V_r, V_i, V_j, V_k = torch.chunk(V, 4, dim=-1)\n","\n","        # Compute quaternion attention weights\n","        attention_weights = self.quaternion_attention(Q, K)\n","\n","        # Apply component-wise softmax normalization\n","        attention_weights_r = F.softmax(attention_weights.r / torch.sqrt(torch.tensor(self.dk, dtype=torch.float32)), dim=-1)\n","        attention_weights_i = F.softmax(attention_weights.i / torch.sqrt(torch.tensor(self.dk, dtype=torch.float32)), dim=-1)\n","        attention_weights_j = F.softmax(attention_weights.j / torch.sqrt(torch.tensor(self.dk, dtype=torch.float32)), dim=-1)\n","        attention_weights_k = F.softmax(attention_weights.k / torch.sqrt(torch.tensor(self.dk, dtype=torch.float32)), dim=-1)\n","\n","        # Apply dropout to the attention weights\n","        attention_weights_r = F.dropout(attention_weights_r, p=self.dropout_rate, training=self.training)\n","        attention_weights_i = F.dropout(attention_weights_i, p=self.dropout_rate, training=self.training)\n","        attention_weights_j = F.dropout(attention_weights_j, p=self.dropout_rate, training=self.training)\n","        attention_weights_k = F.dropout(attention_weights_k, p=self.dropout_rate, training=self.training)\n","\n","        # Apply the attention weights to the V components\n","        attention_r = attention_weights_r @ V_r\n","        attention_i = attention_weights_i @ V_i\n","        attention_j = attention_weights_j @ V_j\n","        attention_k = attention_weights_k @ V_k\n","\n","        # Concatenate the attended quaternion components\n","        attention_output = torch.cat([attention_r, attention_i, attention_j, attention_k], dim=-1)\n","\n","        # If input was 3D, reshape back to original 3D shape\n","        if is_3d_input:\n","            attention_output = attention_output.view(batch_size, seq_len, -1)\n","        return attention_output\n","\n","class MultiHeadQuaternionSelfAttention(nn.Module):\n","    \"\"\"\n","    A PyTorch implementation of multi-head quaternion self-attention.\n","    This module extends the quaternion self-attention mechanism to multiple heads for better representation learning.\n","\n","    Attributes:\n","        input_dim (int): The dimension of the input tensor.\n","        output_dim (int): The total dimension of the output tensor.\n","        num_heads (int): The number of attention heads.\n","        dropout_rate (float): The dropout rate applied to attention weights.\n","    \"\"\"\n","    def __init__(self, input_dim, output_dim, num_heads=4, dropout_rate=0.0):\n","        \"\"\"\n","        Initializes the MultiHeadQuaternionSelfAttention module.\n","\n","        Args:\n","            input_dim (int): The dimension of the input tensor.\n","            output_dim (int): The total dimension of the output tensor. Must be divisible by 4 * num_heads.\n","            num_heads (int): The number of attention heads. Default is 4.\n","            dropout_rate (float): Dropout rate applied to attention weights. Default is 0.0.\n","        \"\"\"\n","        super(MultiHeadQuaternionSelfAttention, self).__init__()\n","\n","        self.output_dim = output_dim\n","        self.num_heads = num_heads\n","        self.input_dim = input_dim\n","\n","        # Ensure output_dim is divisible by 4 * num_heads for quaternion-based operations\n","        assert self.output_dim % (4 * num_heads) == 0, \"output_dim must be divisible by 4 * num_heads.\"\n","\n","        # Compute the output dimension for each head\n","        self.output_dim_per_head = self.output_dim // num_heads\n","\n","        # Dropout rate\n","        self.dropout_rate = dropout_rate\n","\n","        # Create multiple QuaternionSelfAttention instances for each head\n","        self.attention_heads = nn.ModuleList([\n","            QuaternionSelfAttention(input_dim, self.output_dim_per_head, dropout_rate=self.dropout_rate) for _ in range(num_heads)\n","        ])\n","\n","        # Linear transformation to combine the heads' outputs into the final output shape\n","        self.output_transform = QuaternionTransformation(self.output_dim_per_head * num_heads, output_dim // 4)\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Forward pass for multi-head quaternion self-attention.\n","\n","        Args:\n","            X (torch.Tensor): Input tensor of shape [batch_size, seq_len, input_dim].\n","\n","        Returns:\n","            torch.Tensor: Output tensor after applying multi-head quaternion self-attention,\n","                          with shape [batch_size, seq_len, output_dim].\n","        \"\"\"\n","        # Get input tensor dimensions\n","        batch_size, seq_len, input_dim = X.shape\n","\n","        # Split the input tensor across heads along the last dimension\n","        head_inputs = torch.chunk(X, self.num_heads, dim=-1)  # List of [batch_size, seq_len, input_dim / num_heads]\n","\n","        # Apply attention from each head and collect the outputs\n","        head_outputs = []\n","        for i, head in enumerate(self.attention_heads):\n","            # Pass each chunk to a separate attention head\n","            head_output = head(head_inputs[i])  # Shape: [batch_size, seq_len, output_dim_per_head]\n","            head_outputs.append(head_output)\n","\n","        # Concatenate outputs from all heads along the last dimension\n","        multihead_output = torch.cat(head_outputs, dim=-1)  # Shape: [batch_size, seq_len, output_dim_per_head * num_heads]\n","\n","        # Apply a quaternion transformation to combine the heads' outputs into the final output shape\n","        attention_output = self.output_transform(multihead_output)  # Shape: [batch_size, seq_len, output_dim]\n","\n","        return attention_output\n"],"metadata":{"id":"suIotr12cIwG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["I dont do the full quaternion transformer here as we have notice, incoporating quaternion structures **will significantly increase computing time.**"],"metadata":{"id":"Lw9vED20dS-4"}},{"cell_type":"markdown","source":["To implement full you can go to transfomrerblock replacenn.linear with quaternion transformation"],"metadata":{"id":"szgTdB__dpKE"}},{"cell_type":"code","source":["# 4. Model Definition\n","\n","class LearnablePositionalEncoding(nn.Module):\n","    \"\"\"\n","    Positional Encoding with learnable parameters.\n","    Adds positional information to token embeddings.\n","    \"\"\"\n","    def __init__(self, max_len, dmodel, dropout, padding_idx=None):\n","        super(LearnablePositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        self.pos_encoding = nn.Parameter(torch.zeros(1, max_len, dmodel))\n","        nn.init.normal_(self.pos_encoding, mean=0, std=0.1)\n","\n","        if padding_idx is not None:\n","            self.pos_encoding.data[:, padding_idx, :] = 0.0\n","\n","    def forward(self, embedd):\n","        embedd = embedd + self.pos_encoding[:, :embedd.size(1), :]\n","        return self.dropout(embedd)\n","\n","class TransformerBlockQuaternions(nn.Module):\n","    \"\"\"\n","    A Transformer Block consisting of Multi-Head Quaternion Self-Attention and Quaternion Feed-Forward Network.\n","    Includes Layer Normalization and Residual Connections.\n","    \"\"\"\n","    def __init__(self, dmodel, ffnn_hidden_size, num_heads, dropout):\n","        \"\"\"\n","        Initializes the TransformerBlockQuaternions.\n","\n","        Args:\n","            dmodel (int): Dimensionality of the model (must be divisible by 4 * num_heads).\n","            ffnn_hidden_size (int): Hidden size for the Feed-Forward Network (must be divisible by 4).\n","            num_heads (int): Number of quaternion attention heads.\n","            dropout (float): Dropout rate.\n","        \"\"\"\n","        super(TransformerBlockQuaternions, self).__init__()\n","        self.attention = MultiHeadQuaternionSelfAttention(input_dim=dmodel, output_dim=dmodel, num_heads=num_heads, dropout_rate=dropout)\n","        self.layer_norm1 = nn.LayerNorm(dmodel)\n","        self.ffnn = nn.Sequential(\n","            nn.Linear(dmodel, ffnn_hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(ffnn_hidden_size, dmodel)\n","        )\n","        self.layer_norm2 = nn.LayerNorm(dmodel)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the Transformer Block with Quaternion Self-Attention.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor of shape [batch_size, seq_len, dmodel].\n","\n","        Returns:\n","            torch.Tensor: Output tensor of shape [batch_size, seq_len, dmodel].\n","        \"\"\"\n","        # Quaternion Self-Attention\n","        attn_out = self.attention(x)\n","        x = self.layer_norm1(x + self.dropout(attn_out))\n","\n","        # Feed Forward Network\n","        ffnn_out = self.ffnn(x)\n","        x = self.layer_norm2(x + self.dropout(ffnn_out))\n","        return x\n","\n","class QuaternionsTransformerModel(nn.Module):\n","    \"\"\"\n","    A Quaternions-based Transformer model that integrates BERT embeddings with Quaternion Self-Attention and Feed-Forward Networks.\n","    \"\"\"\n","    def __init__(self, pretrained_model_name='bert-base-uncased', output_size=3,\n","                 n_layers=6, ffnn_hidden_size=None, num_heads=4, dropout=0.1, pooling='max'):\n","        \"\"\"\n","        Initializes the QuaternionsTransformerModel.\n","\n","        Args:\n","            pretrained_model_name (str): Name of the pre-trained BERT model.\n","            output_size (int): Number of output classes.\n","            n_layers (int): Number of Transformer blocks.\n","            ffnn_hidden_size (int, optional): Hidden size for the Feed-Forward Network. Defaults to dmodel * 4.\n","            num_heads (int): Number of quaternion attention heads.\n","            dropout (float): Dropout rate.\n","            pooling (str): Pooling method ('max' or 'avg').\n","        \"\"\"\n","        super(QuaternionsTransformerModel, self).__init__()\n","        self.bert = BertModel.from_pretrained(pretrained_model_name)\n","        self.dropout = nn.Dropout(dropout)\n","        self.pooling = pooling\n","\n","        dmodel = self.bert.config.hidden_size  # Typically 768 for bert-base\n","\n","        if ffnn_hidden_size is None:\n","            ffnn_hidden_size = dmodel * 4\n","\n","        # Initialize Positional Encoding\n","        self.pos_encoding = LearnablePositionalEncoding(max_len=512, dmodel=dmodel, dropout=dropout, padding_idx=0)\n","\n","        # Initialize Transformer Blocks with Quaternion Self-Attention\n","        self.blocks = nn.ModuleList([\n","            TransformerBlockQuaternions(dmodel=dmodel, ffnn_hidden_size=ffnn_hidden_size, num_heads=num_heads, dropout=dropout)\n","            for _ in range(n_layers)\n","        ])\n","\n","        # Initialize Layer Normalization\n","        self.layer_norm = nn.LayerNorm(dmodel)\n","\n","        # Final Classification Layer\n","        self.fc = nn.Linear(dmodel, output_size)\n","\n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        Forward pass of the QuaternionsTransformerModel.\n","\n","        Args:\n","            input_ids (torch.Tensor): Input IDs from BERT tokenizer.\n","            attention_mask (torch.Tensor): Attention mask from BERT tokenizer.\n","\n","        Returns:\n","            torch.Tensor: Logits for each class.\n","        \"\"\"\n","        # Get BERT embeddings\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        x = outputs.last_hidden_state  # Shape: [batch_size, seq_len, hidden_size]\n","\n","        # Apply Positional Encoding\n","        x = self.pos_encoding(x)  # Shape: [batch_size, seq_len, hidden_size]\n","\n","        # Apply Dropout\n","        x = self.dropout(x)\n","\n","        # Apply Transformer Blocks\n","        for block in self.blocks:\n","            x = block(x)  # Shape remains [batch_size, seq_len, hidden_size]\n","\n","        # Apply Layer Normalization\n","        x = self.layer_norm(x)\n","\n","        # Pooling\n","        if self.pooling == 'max':\n","            x = F.adaptive_max_pool1d(x.permute(0, 2, 1), 1).view(x.size(0), -1)\n","        else:  # Average Pooling\n","            # To avoid division by zero, add a small epsilon\n","            x = torch.sum(x, dim=1) / (attention_mask.sum(dim=1).unsqueeze(1).float() + 1e-8)\n","\n","        # Final Classification Layer\n","        logits = self.fc(x)\n","        return logits\n"],"metadata":{"id":"e6gsw900dKgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Data Loading\n","\n","def create_dataloader(input_ids, attention_mask, labels, batch_size):\n","    \"\"\"\n","    Creates a PyTorch DataLoader from input IDs, attention masks, and labels.\n","\n","    Args:\n","        input_ids (torch.Tensor): Tensor of input IDs.\n","        attention_mask (torch.Tensor): Tensor of attention masks.\n","        labels (torch.Tensor): Tensor of labels.\n","        batch_size (int): The batch size for the DataLoader.\n","\n","    Returns:\n","        DataLoader: A DataLoader for the given data.\n","    \"\"\"\n","    dataset = TensorDataset(input_ids, attention_mask, labels)\n","    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"yE-oAVFEd280"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  6. Training & Evaluation\n","\n","def train_epoch(model, dataloader, criterion, optimizer, device):\n","    \"\"\"\n","    Trains the model for one epoch.\n","\n","    Args:\n","        model (nn.Module): The model to train.\n","        dataloader (DataLoader): DataLoader for training data.\n","        criterion (nn.Module): Loss function.\n","        optimizer (torch.optim.Optimizer): Optimizer.\n","        device (torch.device): Device to run the training on.\n","\n","    Returns:\n","        float: Average loss over the epoch.\n","    \"\"\"\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in tqdm(dataloader, desc=\"Training\", leave=False):\n","        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    return avg_loss\n","\n","def eval_model(model, dataloader, criterion, device):\n","    \"\"\"\n","    Evaluates the model on a validation or test set.\n","\n","    Args:\n","        model (nn.Module): The model to evaluate.\n","        dataloader (DataLoader): DataLoader for validation/test data.\n","        criterion (nn.Module): Loss function.\n","        device (torch.device): Device to run the evaluation on.\n","\n","    Returns:\n","        tuple: Average loss and accuracy.\n","    \"\"\"\n","    model.eval()\n","    total_loss = 0\n","    correct_preds = 0\n","    total_preds = 0\n","\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n","            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n","            outputs = model(input_ids, attention_mask)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","\n","            _, preds = torch.max(outputs, dim=1)\n","            correct_preds += torch.sum(preds == labels)\n","            total_preds += labels.size(0)\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    avg_loss = total_loss / len(dataloader)\n","    accuracy = correct_preds.double() / total_preds\n","    return avg_loss, accuracy.item(), all_preds, all_labels\n"],"metadata":{"id":"he4ijo86d7gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"metadata":{"id":"Io_QFkchd8HN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 7. Main Workflow\n","\n","\n","# Replace 'your_dataset.csv' with your actual dataset file path.\n","# The dataset should have at least two columns: 'Sentence' and 'Sentiment'.\n","# 'Sentiment' should contain labels like 'neutral', 'positive', 'negative'.\n","\n","# Example:\n","# org_data = pd.read_csv('your_dataset.csv')\n","\n","# import data\n","# org_data = pd.read_csv('data.csv')\n","'''\n","org_data= pd.read_parquet('train-00000-of-00001.parquet', engine='pyarrow')\n","mapping = {0: 'neutral', 1: 'positive', 2: 'negative'}\n","org_data.rename(columns={'label': 'Sentiment', 'text': 'Sentence'}, inplace=True)\n","org_data['Sentiment'] = org_data['Sentiment'].map(mapping)\n","'''\n","\n","org_data = pd.read_csv('data.csv')\n","\n","# Initialize the TextPreprocessor\n","preprocessor = TextPreprocessor(max_len=50)\n","(train_input_ids, train_attention_mask, train_labels,\n","  val_input_ids, val_attention_mask, val_labels,\n","  test_input_ids, test_attention_mask, test_labels) = preprocessor.preprocess_dataset(\n","    org_data, text_column='Sentence', label_column='Sentiment'\n",")\n","\n","# Create DataLoader\n","batch_size = 64  # Adjust based on your hardware capabilities\n","\n","train_loader = create_dataloader(train_input_ids, train_attention_mask, train_labels, batch_size)\n","val_loader = create_dataloader(val_input_ids, val_attention_mask, val_labels, batch_size)\n","test_loader = create_dataloader(test_input_ids, test_attention_mask, test_labels, batch_size)\n","\n","# Initialize Model, Loss, Optimizer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Define model parameters\n","pretrained_model_name = 'bert-base-uncased'\n","output_size = 3  # Number of classes: neutral, positive, negative\n","n_layers = 2     # Number of Transformer blocks; increase for better performance\n","ffnn_hidden_size = None  # If None, defaults to dmodel * 4\n","num_heads = 4    # Number of attention heads\n","dropout = 0.1\n","pooling = 'max'  # 'max' or 'avg'\n","\n","# Initialize the model\n","model = QuaternionsTransformerModel(\n","    pretrained_model_name=pretrained_model_name,\n","    output_size=output_size,\n","    n_layers=n_layers,\n","    ffnn_hidden_size=ffnn_hidden_size,\n","    num_heads=num_heads,\n","    dropout=dropout,\n","    pooling=pooling\n",")\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","\n","# ----------------------------\n","# Training Loop: Warning Quaternion Operation will significantlt increase operating times\n","\n","num_epochs = 10\n","best_val_accuracy = 0\n","\n","import time\n","\n","\n","start_time = time.time()\n","for epoch in range(num_epochs):\n","    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n","\n","    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n","    val_loss, val_accuracy, val_preds, val_labels_true = eval_model(model, val_loader, criterion, device)\n","\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Save the model if validation accuracy improves\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        torch.save(model.state_dict(), 'best_quaternions_transformer.pt')\n","        print(\"Model saved.\")\n","end_time = time.time()\n","print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n","# ----------------------------\n","# Evaluation on Test Set\n","\n","# Load the best model\n","model.load_state_dict(torch.load('best_quaternions_transformer.pt'))\n","\n","test_loss, test_accuracy, test_preds, test_labels_true = eval_model(model, test_loader, criterion, device)\n","print(f\"\\nTest Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n","\n","# Detailed Classification Report\n","print(\"\\nClassification Report:\")\n","print(classification_report(test_labels_true, test_preds, target_names=['neutral', 'positive', 'negative']))\n","\n","# Confusion Matrix\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(test_labels_true, test_preds))\n","\n","print(count_parameters(model))\n"],"metadata":{"id":"h51nEan7eCFD","executionInfo":{"status":"ok","timestamp":1741753126579,"user_tz":240,"elapsed":390326,"user":{"displayName":"Wenda Zhai","userId":"16839433519852049027"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e37e8f3f915242d5b64dc0b84c015cb5","0d5f5f25dc244940ab8ca8ed26b834f7","297f2686f538448aa3305beeb831aa89","4b895e1f43ae42978cd9c91fde195b42","a3ca77e672da4665bfbbab6c20a7654e","5b51aaccbfcb4ac799a519cd6e18cfd0","26cf6ceeb94b4de7bda633bfe665a534","ffe5a47a9fcd4f9ab1186c3fc3c47cb3","e01fb8997e7e48e1a79dcd4792573ab7","17a666ec765d4a36b7ef20115fef6c79","9bd287d28c8d4976916e5da4a755d135","417537fcf82b4346b171b29b46f82ae0","4b08f431f15941f5b0ecd6595e774907","7f2c9ee2d800465f989b01c2fe151218","1fd99f18b21045eaa714ab8197d4720e","04a8b0c0e233412094d43663eaea68ff","8ec855b173b146f1ad1145fad9df3a90","c9ebc61956bc4d40a5fc258f9f4a15ef","2b5b232b7e2a4c66a6e6a7c8901e9dc8","c5d312fb4e1641a5a7bea62456f99fe9","2beb79c0627c4c6a9122f9b68314316a","f4f49846947241a880e62d8b13bd6c83","f116221591694a4aa6cc4b6a04ce7057","beb12108bca74231b1c58654bc4adbb7","8744eea355b74bab80ee82740e7baed7","0cd16a761cb744b6916d89f9097c593b","acdcdcadc6e443df901a2683e6226985","b480be75f62b42b19687fa099ff3207f","dedc68cdcccf474ca6ea94aec29a01bc","cb166bddc11849c092814e973f71853f","8cb97e58aef44180963934a86f78eecf","4e683db92ba842e2b0931c248a32fa51","e35dc6e9f7de428c87660938787767e5","dce708aad43c4c9fae5a4c18a6f23aa8","483acd5b8c7f46cfbd9057c474cc6b5f","65d6a762fd99478da40d0e618538f7bf","210c59458a67461b9495e43c5476aaa4","07b30e9c7ae145b7b521b585bff8bda8","354aceb6f167459a922854027bf922fc","cd0167a109ec4d4a91269ed8c49e6c8c","9aa113c1656f4e598ddea9eafcbf579c","2053ed0518c9487fbdd61cdfd56585b5","66b4a8f908b8480291001dd0bc9894c9","7f050f5ad4de4bb4a5ee5d5c07f5994e","0018c5600e7d4661a9ac2f4408e962a8","7b97caa1554548168034073f5e7fe85a","7a856d561fe2478d9430fe786e7d35c9","5e52dd92421a47eebc9b4b3082800cca","549f233266554201851b3dcfdd5ff1c3","321d72eb76e7454db8f9f0911a5eba64","1251476a0805423082651f0d2613c0cf","aae3ccf74ae7480ab7c621ece617e8d5","34c2764c9cd5475a9c0186bf762b6e9a","cfa8a7bd49954c4db916933f148203de","5e2dbe7133b340059e7456f85d2afa1b"]},"outputId":"8f4d3325-f1a7-4e83-d054-f4cab40b39ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e37e8f3f915242d5b64dc0b84c015cb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"417537fcf82b4346b171b29b46f82ae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f116221591694a4aa6cc4b6a04ce7057"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce708aad43c4c9fae5a4c18a6f23aa8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Cleaning text data...\n","Encoding labels...\n","Splitting dataset into train, validation, and test sets...\n","Tokenizing and encoding text data...\n","Train set: 3505 samples\n","Validation set: 1168 samples\n","Test set: 1169 samples\n","Using device: cuda\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0018c5600e7d4661a9ac2f4408e962a8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.9614\n","Validation Loss: 0.9904 | Validation Accuracy: 0.5993\n","Model saved.\n","\n","Epoch 2/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6961\n","Validation Loss: 0.7212 | Validation Accuracy: 0.7080\n","Model saved.\n","\n","Epoch 3/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4886\n","Validation Loss: 0.5289 | Validation Accuracy: 0.7603\n","Model saved.\n","\n","Epoch 4/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3778\n","Validation Loss: 0.6074 | Validation Accuracy: 0.7783\n","Model saved.\n","\n","Epoch 5/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.2939\n","Validation Loss: 0.6313 | Validation Accuracy: 0.7765\n","\n","Epoch 6/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.2491\n","Validation Loss: 0.6080 | Validation Accuracy: 0.7851\n","Model saved.\n","\n","Epoch 7/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.1941\n","Validation Loss: 0.7208 | Validation Accuracy: 0.7954\n","Model saved.\n","\n","Epoch 8/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.1723\n","Validation Loss: 0.8705 | Validation Accuracy: 0.7731\n","\n","Epoch 9/10\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.1592\n","Validation Loss: 0.7122 | Validation Accuracy: 0.7688\n","\n","Epoch 10/10\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-3240e25c8f26>:96: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('best_quaternions_transformer.pt'))\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.1680\n","Validation Loss: 0.7441 | Validation Accuracy: 0.7808\n","Total training time: 376.34 seconds\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["\n","Test Loss: 0.7829 | Test Accuracy: 0.7887\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","     neutral       0.78      0.92      0.84       626\n","    positive       0.82      0.83      0.82       371\n","    negative       0.74      0.22      0.33       172\n","\n","    accuracy                           0.79      1169\n","   macro avg       0.78      0.66      0.67      1169\n","weighted avg       0.78      0.79      0.76      1169\n","\n","Confusion Matrix:\n","[[578  43   5]\n"," [ 56 307   8]\n"," [109  26  37]]\n","119846403\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import numpy as np\n","confusion_matrix=np.array([[482,56,88],[38,318,15],[45,23,104]])\n","disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[\"Neutral\",\"Positive\",\"Negative\"])\n","plt.figure(figsize=(10,10),dpi=200)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title(\"Quaternion Transformer Model Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"I1jDjBu-Yy78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U0BREJHOb3TU"},"execution_count":null,"outputs":[]}]}